
@inproceedings{abel-EtAl:2016:koko,
  title = {An extended version of the {{KoKo German L1 Learner}} corpus},
  booktitle = {Proceedings of {{Third Italian Conference}} on {{Computational Linguistics}} ({{CLiC}}-it 2016) \& {{Fifth Evaluation Campaign}} of {{Natural Language Processing}} and {{Speech Tools}} for {{Italian}}. {{Final Workshop}} ({{EVALITA}} 2016)},
  author = {Abel, Andrea and Glaznieks, Aivars and Nicolas, Lionel and Stemle, Egon},
  editor = {Basile, Pierpaolo and Corazza, Anna and Cutugno, Franco and Montemagni, Simonetta and Nissim, Malvina and Patti, Viviana and Semeraro, Giovanni and Sprugnoli, Rachele},
  date = {2016-12},
  location = {{Napoli, Italy}},
  doi = {10.4000/books.aaccademia.1743},
  url = {http://books.openedition.org/aaccademia/pdf/1743},
  abstract = {This paper describes an extended version of the KoKo corpus (version KoKo4, Dec 2015), a corpus of written German L1 learner texts from three different German-speaking regions in three different countries. The KoKo corpus is richly annotated with learner language features on different linguistic levels such as errors or other linguistic characteristics that are not deficit-oriented, and is enriched with a wide range of metadata. This paper complements a previous publication (Abel et al., 2014a) and reports on new textual metadata and lexical annotations and on the methods adopted for their manual annotation and linguistic analyses. It also briefly introduces some linguistic findings that have been derived from the corpus.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/VW9AYPJS/abel_et_al_2016_an_extended_version_of_the_koko_german_l1_learner_corpus.pdf}
>>>>>>> 1faf962... Sync
}

@inproceedings{abel-stemle:2018:euralex,
  title = {On the {{Detection}} of {{Neologism Candidates}} as {{Basis}} for {{Language Observation}} and {{Lexicographic Endeavours}}: {{The STyrLogism Project}}},
  booktitle = {Proceedings of the {{XVIII EURALEX International Congress}}: {{Lexicography}} in {{Global Contexts}}},
  author = {Abel, Andrea and Stemle, Egon W.},
  editor = {Čibej, Jaka and Gorjanc, Vojko and Kosem, Iztok and Krek, Simon},
  date = {2018-08},
  pages = {535--544},
  publisher = {{Ljubljana University Press, Faculty of Arts}},
  location = {{Ljubljana, SI}},
  url = {https://api.zotero.org/users/332053/publications/items/SSDTBJ6N/file/view},
  abstract = {The goal of the project STyrLogisms is to semi-automatically extract neologism (new lexemes) candidates for the German standard variety used in South Tyrol. We use a list of manually vetted URLs from news, magazines and blog websites of South Tyrol and regularly crawl their data, clean and process it and compare this new data to reference corpora and additional regional word lists and the formerly crawled data sets. Our reference corpora are DECOW14 with around 60m types, and the South Tyrolean Web Corpus with around 2.4m types; the additional word lists consist of named entities, terminological terms from the region, and specific terms of the German standard variety used in South Tyrol (altogether around 53k unique types). Here, we will report on the employed method, a first round of candidate extraction with an approach for a classification schema for the selected candidates, and some remarks on a second extraction round.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/SSDTBJ6N/abel_stemle_2018_on_the_detection_of_neologism_candidates_as_basis_for_language_observation_and.pdf},
>>>>>>> 1faf962... Sync
  isbn = {978-961-06-0097-8}
}

@inproceedings{ABEL14.934,
  title = {{{KoKo}}: {{An L1 Learner Corpus}} for {{German}}},
  booktitle = {Proceedings of the {{Ninth International Conference}} on {{Language Resources}} and {{Evaluation}} ({{LREC}}'14)},
  author = {Abel, Andrea and Glaznieks, Aivars and Nicolas, Lionel and Stemle, Egon},
  editor = {Calzolari, Nicoletta and Choukri, Khalid and Declerck, Thierry and Loftsson, Hrafn and Maegaard, Bente and Mariani, Joseph and Moreno, Asuncion and Odijk, Jan and Stelios, Piperidis},
  date = {2014-05},
  pages = {2414--2421},
  publisher = {{European Language Resources Association (ELRA)}},
  location = {{Reykjavik, Iceland}},
  url = {http://www.lrec-conf.org/proceedings/lrec2014/pdf/934_Paper.pdf},
  abstract = {We introduce the KoKo corpus, a collection of German L1 learner texts annotated with learner errors, along with the methods and tools used in its construction and evaluation. The corpus contains both texts and corresponding survey information from 1,319 pupils and amounts to around 716,000 tokens. The evaluation of the quality of the performed transcriptions and annotations shows an accuracy of orthographic error annotations of approximately 80\% as well as high accuracy of transcriptions ({$>$} 99\%), automatic tokenisation ({$>$} 99\%), sentence splitting ({$>$} 96\%) and POS-tagging ({$>$} 94\%). The KoKo corpus will be published at the end of 2014 and be the first accessible linguistically annotated German L1 learner corpus. It will represent a valuable source for research and teaching on German as L1 language, in particular with regards to writing skills.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/BBV3DMG7/abel_et_al_2014_koko.pdf},
>>>>>>> 1faf962... Sync
  isbn = {978-2-9517408-8-4},
  keywords = {German Language,Learner Corpora}
}

@report{ASADO2005,
  title = {{{ASADO}}: {{The Analysis}} and {{Structuring}} of {{Aviation Documents}} - {{Final Report}}},
  author = {Bleichner, Martin and Giesbrecht, Eugenie and Gust, Helmar and Leicht, Eva-Maria and Ludewig, Petra and Möller, Sabine and Müller, Wiebke and Schmidt, Martin and Stefaner, Moritz and Stemle, Egon and Wilke, Katja},
  date = {2005-11},
  institution = {{Institute of Cognitive Science at the University of Osnabrück and Institute of Applied Linguistics at the University of Hildesheim}},
  url = {https://api.zotero.org/users/332053/publications/items/KSJ9ECLV/file/view},
  abstract = {Final Report of the one year cooperation between the Universities of Osnabrück and Hildesheim, and the aircraft manufacturer AIRBUS to research methodologies and technologies to analyze and structure the huge amount of documentation produced during aircraft construction. The work was done in a study project carried out in close cooperation with seven students of cognitive science advised by two lectures of the Institute of Cognitive Science of the University of Osnabrück and with one student of international information management advised by one professor of the Institute of Applied Linguistics of the University of Hildesheim.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/KSJ9ECLV/bleichner_et_al_2005_asado.pdf}
>>>>>>> 1faf962... Sync
}

@inproceedings{beisswenger-EtAl:2016:clarin,
  title = {Integrating corpora of computer-mediated communication into the language resources landscape: {{Initiatives}} and best practices from {{French}}, {{German}}, {{Italian}} and {{Slovenian}} projects},
  booktitle = {Proceedings of the {{CLARIN Annual Conference}} 2016},
  author = {Beißwenger, Michael and Chanier, Thierry and Chiari, Isabella and Erjavec, Tomaž and Fišer, Darja and Herold, Axel and Lubešić, Nikola and Lüngen, Harald and Poudat, Céline and Stemle, Egon and Storrer, Angelika and Wigham, Ciara},
  date = {2016-10},
  url = {https://api.zotero.org/users/332053/publications/items/6U6JVTK3/file/view},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/6U6JVTK3/beißwenger_et_al_2016_integrating_corpora_of_computer-mediated_communication_into_the_language.pdf},
>>>>>>> 1faf962... Sync
  keywords = {CMC corpora,community building,computer-mediated communication,corpus annotation,language resources,social media corpora,TEI}
}

@inproceedings{beisswenger-EtAl:2016:clarin-long,
  title = {Closing a {{Gap}} in the {{Language Resources Landscape}}: {{Groundwork}} and {{Best Practices}} from {{Projects}} on {{Computer}}-mediated {{Communication}} in four {{European Countries}}},
  booktitle = {Selected {{Papers}} from the {{CLARIN Annual Conference}} 2016, {{Aix}}-en-{{Provence}}, 26–28 {{October}} 2016, {{CLARIN Common Language Resources}} and {{Technology Infrastructure}}},
  author = {Beißwenger, Michael and Chanier, Thierry and Erjavec, Tomaž and Fišer, Darja and Herold, Axel and Lubešić, Nikola and Lüngen, Harald and Poudat, Céline and Stemle, Egon and Storrer, Angelika and Wigham, Ciara},
  editor = {Borin, Lars},
  date = {2017-05-23},
  volume = {136},
  pages = {1--18},
  publisher = {{Linköping University Electronic Press, Linköpings universitet}},
  location = {{Aix-en-Provence, FR}},
  issn = {1650-3740},
  url = {https://hal.archives-ouvertes.fr/hal-01379621/document},
  abstract = {The paper presents best practices and results from projects dedicated to the creation of corpora of computer-mediated communication and social media interactions (CMC) from four different countries. Even though there are still many open issues related to building and annotating corpora of this type, there already exists a range of tested solutions which may serve as a starting point for a comprehensive discussion on how future standards for CMC corpora could (and should) be shaped like.},
  eventtitle = {{{CLARIN Annual Conference}} 2016},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/H9SS5LYQ/beiswenger_et_al_2017_closing_a_gap_in_the_language_resources_landscape.pdf},
>>>>>>> 1faf962... Sync
  isbn = {978-91-7685-499-0},
  keywords = {CMC corpora,community building,computer-mediated communication,corpus annotation,language resources,social media corpora,TEI},
  series = {Linköping {{Electronic Conference Proceedings}}}
}

@inproceedings{beisswenger-EtAl:2017:cmc-corpora,
  title = {Connecting {{Resources}}: {{Which Issues}} have to be {{Solved}} to {{Integrate CMC Corpora}} from {{Heterogeneous Sources}} and for {{Different Languages}}?},
  booktitle = {Proceedings of the 5th {{Conference}} on {{CMC}} and {{Social Media Corpora}} for the {{Humanities}}},
  author = {Beißwenger, Michael and Wigham, Ciara R. and Etienne, Carole and Fišer, Darja and Suárez, Holger Grumt and Herzberg, Laura and Hinrichs, Erhard and Horsmann, Tobias and Karlova-Bourbonus, Natali and Lemnitzer, Lothar and Longhi, Julien and Lüngen, Harald and Ho-Dac, Lydia-Mai and Parisse, Christophe and Poudat, Céline and Schmidt, Thomas and Stemle, Egon and Storrer, Angelika and Zesch, Torsten},
  editor = {Stemle, Egon W. and Wigham, Ciara},
  date = {2017-10},
  pages = {52--55},
  location = {{Bolzano, Italy}},
  doi = {10.5281/zenodo.1041877},
  url = {https://zenodo.org/record/1041877/files/cmccorpora17-28.pdf},
  abstract = {The paper reports on the results of a scientific colloquium dedicated to the creation of standards and best practices which are needed to facilitate the integration of language resources for CMC stemming from different origins and the linguistic analysis of CMC phenomena in different languages and genres. The key issue to be solved is that of interoperability – with respect to the structural representation of CMC genres, linguistic annotations metadata, and anonymization/pseudonymization schemas. The objective of the paper is to convince more projects to partake in a discussion about standards for CMC corpora and for the creation of a CMC corpus infrastructure across languages and genres. In view of the broad range of corpus projects which are currently underway all over Europe, there is a great window of opportunity for the creation of standards in a bottom-up approach.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/DMSUNENI/beiswenger_et_al_2017_connecting_resources.pdf},
>>>>>>> 1faf962... Sync
  keywords = {annotation,anonymization,corpora,research infrastructures}
}

@inproceedings{BlohmCimianoStemle2007,
  title = {Harvesting {{Relations}} from the {{Web}} - {{Quantifiying}} the {{Impact}} of {{Filtering Functions}}},
  booktitle = {Proceedings of the 22nd {{Conference}} on {{Artificial Intelligence}} ({{AAAI}}-07)},
  author = {Blohm, Sebastian and Cimiano, Philipp and Stemle, Egon},
  date = {2007-07},
  pages = {1316--1323},
  publisher = {{Association for the Advancement of Artificial Intelligence}},
  url = {http://www.aaai.org/Papers/AAAI/2007/AAAI07-208.pdf},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/4QAUX7TL/blohm_et_al_2007_harvesting_relations_from_the_web_-_quantifiying_the_impact_of_filtering.pdf},
>>>>>>> 1faf962... Sync
  isbn = {978-1-57735-323-2}
}

@inproceedings{BoninEtAl:2012:AnnotatingArchaeologicalTexts,
  title = {Annotating {{Archaeological Texts}}: {{An Example}} of {{Domain}}-{{Specific Annotation}} in the {{Humanities}}},
  booktitle = {Proceedings of the {{Sixth Linguistic Annotation Workshop}} ({{LAW}} 2012)},
  author = {Bonin, Francesca and Cavulli, Fabio and Noriller, Aronne and Poesio, Massimo and Stemle, Egon W.},
  date = {2012-07},
  pages = {134--138},
  publisher = {{Association for Computational Linguistics}},
  location = {{Jeju, Republic of Korea}},
  url = {https://www.aclweb.org/anthology/W12-3618},
  abstract = {Developing content extraction methods for Humanities domains raises a number of chal- lenges, from the abundance of non-standard entity types to their complexity to the scarcity of data. Close collaboration with Humani- ties scholars is essential to address these chal- lenges. We discuss an annotation schema for Archaeological texts developed in collabora- tion with domain experts. Its development re- quired a number of iterations to make sure all the most important entity types were included, as well as addressing challenges including a domain-specific handling of temporal expres- sions, and the existence of many systematic types of ambiguity.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/K36FGHHW/bonin_et_al_2012_annotating_archaeological_texts.pdf},
>>>>>>> 1faf962... Sync
  issue = {July},
  series = {{{LAW VI}} '12}
}

@book{cmc-corpora:2017,
  title = {Proceedings of the 5th {{Conference}} on {{CMC}} and {{Social Media Corpora}} for the {{Humanities}}},
  editor = {Stemle, Egon W. and Wigham, Ciara R.},
  date = {2017-10},
  location = {{Bolzano, Italy}},
  doi = {10.5281/zenodo.1040875},
  url = {https://zenodo.org/record/1040875/files/cmccorpora17-proceedings-v2.pdf},
  abstract = {This volume presents the proceedings of the 5th edition of the annual conference series on CMC and Social Media Corpora for the Humanities (cmc-corpora2017). This conference series is dedicated to the collection, annotation, processing, and exploitation of corpora of computer-mediated communication (CMC) and social media for research in the humanities. The annual event brings together language-centered research on CMC and social media in linguistics, philologies, communication sciences, media and social sciences with research questions from the fields of corpus and computational linguistics, language technology, text technology, and machine learning. The 5th Conference on CMC and Social Media Corpora for the Humanities was held at Eurac Research on October, 4th and 5th, in Bolzano, Italy. This volume contains extended abstracts of the invited talks, papers, and extended abstracts of posters presented at the event. The conference attracted 26 valid submissions. Each submission was reviewed by at least two members of the scientific committee. This committee decided to accept 16 papers and 8 posters of which 14 papers and 3 posters were presented at the conference. The programme also includes three invited talks: two keynote talks by Aivars Glaznieks (Eurac Research, Italy) and A. Seza Doğruöz (Independent researcher) and an invited talk on the Common Language Resources and Technology Infrastructure (CLARIN) given by Darja Fišer, the CLARIN ERIC Director of User Involvement.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/QIL43SW7/stemle_wigham_2017_proceedings_of_the_5th_conference_on_cmc_and_social_media_corpora_for_the.pdf},
>>>>>>> 1faf962... Sync
  langid = {english},
  type = {proceedings}
}

@article{egartervigl-stemle:2018:WasDarfForschung,
  title = {Was darf Forschung mit Social Media Daten?},
  author = {Baumgartner, Barbara and Angler, Martin},
  date = {2018-05},
  journaltitle = {Academia-Interview Titelthema},
  pages = {10--11},
  url = {http://www.academia.bz.it/articles/was-darf-forschung-mit-social-media-daten},
  abstract = {Interview in Academia (science magazine by EURAC and unibz), Bolzano, Italy},
  editora = {Egarter Vigl, Lukas and Stemle, Egon},
  editoratype = {collaborator},
  entrysubtype = {newspaper},
  langid = {german}
}

@article{EkbalEtAl:2011,
  title = {Rapid {{Adaptation}} of {{NE Resolvers}} for {{Humanities Domains}} using {{Active Annotation}}},
  author = {Ekbal, Asif and Bonin, Francesca and Saha, Sriparna and Stemle, Egon and Barbu, Eduard and Cavulli, Fabio and Girardi, Christian and Poesio, Massimo},
  date = {2011-11},
  journaltitle = {Journal for Language Technology and Computational Linguistics},
  shortjournal = {JLCL},
  volume = {26},
  pages = {39--51},
  issn = {2190-6858},
  url = {https://api.zotero.org/users/332053/publications/items/6KYWUTKC/file/view},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/6KYWUTKC/ekbal_et_al_2011_rapid_adaptation_of_ne_resolvers_for_humanities_domains_using_active_annotation.pdf},
>>>>>>> 1faf962... Sync
  number = {2},
  url_publisher = {https://jlcl.org/}
}

@report{elbers-EtAl:2019:clarin,
  title = {The {{CLARIN ERIC}} deployment infrastructure and its applicability to reproducible research},
  author = {Elbers, Willem and Stemle, Egon W. and Moreira, André and König, Alexander and Cattani, Luca and Palma, Martin},
  date = {2019-11-28},
  institution = {{Zenodo}},
  doi = {10.5281/zenodo.3556747},
  url = {https://zenodo.org/record/3556747},
  urldate = {2019-12-02},
  abstract = {This paper is describing the needs and technological preconditions of the CLARIN ERIC infrastructure. It introduces how containerization using Docker can help to meet these requirements and fleshes out the build and deployment workflow that CLARIN ERIC is employing to ensure that all the goals of their infrastructure are met in an efficient and sustainable way. In a second step, it is also shown how these same workflows can help researchers, especially in the fields of computational and corpus linguistics, to provide for more easily reproducible research by creating a virtual environment that can provide specific versions of data, programs and algorithms used for certain research questions and make sure that the exact same versions can still be used at a later stage to reproduce the results.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/QGI8EB5G/The_CLARIN_ERIC_deployment_infrastructure_and_its_applicability_to_reproducible_research.pdf},
>>>>>>> 1faf962... Sync
  keywords = {best practices,CLARIN,containerization,docker,infrastructure,reproducible research},
  langid = {english}
}

@inproceedings{FIASCO2007,
  title = {{{FIASCO}}: {{Filtering}} the {{Internet}} by {{Automatic Subtree Classification}}, {{Osnabrück}}},
  booktitle = {Proceedings of the {{Third Web}} as {{Corpus Workshop}} ({{WAC3}})},
  author = {Bauer, Daniel and Degen, Judith and Deng, Xiaoye and Herger, Priska and Gasthaus, Jan and Giesbrecht, Eugenie and Jansen, Lina and Kalina, Christin and Krüger, Thorben and Märtin, Robert and Schmidt, Martin and Scholler, Simon and Steger, Johannes and Stemle, Egon and Evert, Stefan},
  editor = {Fairon, Cédrick and Naets, Hubert and Kilgarriff, Adam and family=Schryver, given=Gilles-Maurice, prefix=de, useprefix=true},
  date = {2007-09},
  publisher = {{Presses universitaires de Louvain}},
  location = {{Louvain-la-Neuve}},
  url = {http://purl.org/stefan.evert/PUB/BauerEtc2007_FIASCO.pdf},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/UAUUUYMX/bauer_et_al_2007_fiasco.pdf}
>>>>>>> 1faf962... Sync
}

@inproceedings{frey-EtAl:2019:cmc-corpora,
  title = {How {{FAIR}} are {{CMC Corpora}}?},
  booktitle = {Proceedings of the 7th {{Conference}} on {{CMC}} and {{Social Media Corpora}} for the {{Humanities}} ({{CMC}}-{{Corpora2019}})},
  author = {Frey, Jennifer-Carmen and König, Alexander and Stemle, Egon W.},
  date = {2019-09-09},
  pages = {25--30},
  location = {{Cergy-Pontoise University, France}},
  url = {https://cmccorpora19.sciencesconf.org/resource/page/id/15},
  abstract = {In recent years, research data management has also become an important topic in the less data-intensive areas of the Social Sciences and Humanities (SSH). Funding agencies as well as research communities demand that empirical data collected and used for scientific research is managed and preserved in a way that research results are reproducible. In order to account for this the FAIR guiding principles for data stewardship have been established as a framework for good data management, aiming at the findability, accessibility, interoperability, and reusability of research data. This article investigates 24 European CMC corpora with regard to their compliance with the FAIR principles and discusses to what extent the deposit of research data in repositories of data preservation initiatives such as CLARIN, Zenodo or Metashare can assist in the provision of FAIR corpora.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/QCRXF8RE/frey_et_al_2019_how_fair_are_cmc_corpora.pdf},
>>>>>>> 1faf962... Sync
  urlpdf = {https://api.zotero.org/users/332053/publications/items/QCRXF8RE/file/view},
  urltype = {publisher}
}

@incollection{frey-EtAl:2019:cmc2017volume,
  title = {Comparison of {{Automatic}} vs. {{Manual Language Identification}} in {{Multilingual Social Media Texts}}},
  booktitle = {Building {{Computer}}-{{Mediated Communication Corpora}} for sociolinguistic {{Analysis}}},
  author = {Frey, Jennifer-Carmen and Stemle, Egon W. and Doğruöz, A. Seza},
  editor = {Wigham, Ciara R. and Stemle, Egon W.},
  date = {2019-06-13},
  publisher = {{Presses Universitaires Blaise Pascal}},
  location = {{Clermont-Ferrand, FR}},
  url = {http://pubp.giantchair.com/livre/?GCOI=28451100141150&language=en},
  abstract = {Multilingual speakers communicate in more than one language in daily life and on social media. In order to process or investigate multilingual communication, there is a need for language identification. This study compares the performance of human annotators with automatic ways of language identification on a multilingual (mainly German-Italian-English) social media data set collected in Italy (i.e. South Tyrol). Our results indicate that humans and NLP systems follow their individual techniques to make a decision about multilingual text messages. This results in low agreement when different annotators or NLP systems execute the same task. In general, annotators agree with each other more than NLP systems. However, there is also variation in human agreement depending on the prior establishment of guidelines for the annotation task or not.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/ZHUH69N9/frey_et_al_2019_comparison_of_automatic_vs.pdf;/home/egon/Books/zotero/linked/Frey et al/2019_Book Section/frey_et_al_2019_comparison_of_automatic_vs.pdf},
>>>>>>> 1faf962... Sync
  isbn = {978-2-84516-860-2},
  langid = {english},
  series = {Cahiers du laboratoire de recherche sur le langage},
  urlpdf = {https://api.zotero.org/users/332053/publications/items/ZHUH69N9/file/view},
  urltype = {publisher}
}

@incollection{frey-EtAl:2020:FAIRIndexCMC,
  title = {The {{FAIR Index}} of {{CMC Corpora}}},
  booktitle = {{{CMC Corpora}} through the prism of digital humanities},
  author = {Frey, Jennifer-Carmen and König, Alexander and Stemle, Egon and Falaise, Achille and Fišer, Darja and Lüngen, Harald},
  editor = {Longhi, Julien and Marinica, Claudia},
  date = {2020-05-01},
  publisher = {{L'Harmattan}},
  url = {https://api.zotero.org/users/332053/publications/items/R7Z5VHA2/file/view},
  abstract = {In this article, we examine the current situation of data dissemination and provision for CMC corpora. By that we aim to give a guiding grid for future projects that will improve the transparency and replicability of research results as well as the reusability of the created resources. Based on the FAIR guiding principles for research data management, we evaluate the 20 European CMC corpora listed in the CLARIN CMC Resource family, individuate successful strategies among the existing corpora and establish best practices for future projects. We give an overview of existing approaches to data referencing, dissemination and provision in European CMC corpora, and discuss the methods, formats and strategies used. Furthermore, we discuss the need for community standards and offer recommendations for best practices when creating a new CMC corpus.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/R7Z5VHA2/frey_et_al_2020_the_fair_index_of_cmc_corpora2.pdf;/home/egon/Books/zotero/linked/Frey et al/2020_Book Section/frey_et_al_2020_the_fair_index_of_cmc_corpora.pdf},
>>>>>>> 1faf962... Sync
  isbn = {978-2-343-20250-1},
  series = {Humanités numériques}
}

@inproceedings{frey-glaznieks-stemle:2016:didi,
  title = {The {{DiDi Corpus}} of {{South Tyrolean CMC Data}}: {{A}} multilingual corpus of {{Facebook}} texts},
  booktitle = {Proceedings of {{Third Italian Conference}} on {{Computational Linguistics}} ({{CLiC}}-it 2016) \& {{Fifth Evaluation Campaign}} of {{Natural Language Processing}} and {{Speech Tools}} for {{Italian}}. {{Final Workshop}} ({{EVALITA}} 2016)},
  author = {Frey, Jennifer-Carmen and Glaznieks, Aivars and Stemle, Egon W.},
  editor = {Basile, Pierpaolo and Corazza, Anna and Cutugno, Franco and Montemagni, Simonetta and Nissim, Malvina and Patti, Viviana and Semeraro, Giovanni and Sprugnoli, Rachele},
  date = {2016-12},
  location = {{Napoli, Italy}},
  issn = {1613-0073},
  doi = {10.4000/books.aaccademia.1782},
  url = {https://books.openedition.org/aaccademia/1782},
  abstract = {The DiDi corpus of South Tyrolean data of computer-mediated communication (CMC) is a multilingual sociolinguistic language corpus. It consists of around 600,000 tokens collected from 136 profiles of Facebook users residing in South Tyrol, Italy. In conformity with the multilingual situation of the territory, the main languages of the corpus are German and Italian (followed by English). The data has been manually anonymised and provides manually corrected part-of-speech tags for the Italian language texts and manually normalised data for German texts. Moreover, it is annotated with user-provided socio-demographic data (among others L1, gender, age, education, and internet communication habits) from a questionnaire, and linguistic annotations regarding CMC phenomena, languages and varieties. The anonymised corpus is freely available for research purposes.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/7S8B622Q/frey_et_al_2016_the_didi_corpus_of_south_tyrolean_cmc_data.pdf}
>>>>>>> 1faf962... Sync
}

@inproceedings{FreyGlaznieksStemle2015,
  title = {The {{DiDi Corpus}} of {{South Tyrolean CMC Data}}},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Natural Language Processing}} for {{Computer}}-{{Mediated Communication}} / {{Social Media}} at {{GSCL2015}} ({{NLP4CMC2015}})},
  author = {Frey, Jennifer-Carmen and Glaznieks, Aivars and Stemle, Egon W.},
  date = {2015-09-29},
  pages = {1--6},
  publisher = {{German Society for Computational Linguistics \& Language Technology}},
  location = {{Essen, Germany}},
  url = {https://api.zotero.org/users/332053/publications/items/M7SPS558/file/view},
  abstract = {This paper presents the DiDi Corpus, a corpus of South Tyrolean Data of Computer-mediated Communication (CMC). The corpus comprises around 650,000 tokens from Facebook wall posts, comments on wall posts and private messages, as well as socio-demographic data of participants. All data was automatically annotated with language information (de, it, en and others), and manually normalised and anonymised. Furthermore, semi-automatic token level annotations include part-of-speech and CMC phenomena (e.g. emoticons, emojis, and iteration of graphemes and punctuation). The anonymised corpus without the private messages is freely available for researchers; the complete and anonymised corpus is available after signing a non- disclosure agreement.},
  eventtitle = {2nd {{Workshop}} on {{Natural Language Processing}} for {{Computer}}-{{Mediated Communication}} / {{Social Media}} at {{GSCL2015}} ({{NLP4CMC2015}})},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/M7SPS558/frey_et_al_2015_the_didi_corpus_of_south_tyrolean_cmc_data.pdf}
>>>>>>> 1faf962... Sync
}

@inproceedings{FreyStemleGlaznieks2014,
  title = {Collecting language data of non-public social media profiles},
  booktitle = {Workshop {{Proceedings}} of the 12th {{Edition}} of the {{KONVENS Conference}}},
  author = {Frey, Jennifer-Carmen and Stemle, Egon W. and Glaznieks, Aivars},
  editor = {Faaß, Gertrud and Ruppenhofer, Josef},
  date = {2014-10},
  pages = {11--15},
  publisher = {{Universitatsverlag Hildesheim, Germany}},
  location = {{Hildesheim, Germany}},
  url = {https://api.zotero.org/users/332053/publications/items/REJBNPYM/file/view},
  urldate = {2019-06-20},
  abstract = {In this paper, we propose an integrated web strategy for mixed sociolinguistic research methodologies in the context of social media corpora. After stating the particular challenges for building corpora of private, non-public computer-mediated communication, we will present our solution to these problems: a Facebook web application for the acquisition of such data and the corresponding meta data. Finally, we will discuss positive and negative implications for this method.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/REJBNPYM/frey_et_al_2014_collecting_language_data_of_non-public_social_media_profiles.pdf}
>>>>>>> 1faf962... Sync
}

@inproceedings{GenereuxStemleNicolasLyding2014,
  title = {Correcting {{OCR}} errors for {{German}} in {{Fraktur}} font},
  booktitle = {Proceedings of the {{First Italian Conference}} on {{Computational Linguistics}} ({{CLiC}}-it 2014)},
  author = {Généreux, Michel and Stemle, Egon W. and Nicolas, Lionel and Lyding, Verena},
  editor = {Basili, Roberto and Lenci, Alessandro and Magnini, Bernardo},
  date = {2014-12},
  location = {{Pisa, Italy}},
  url = {https://api.zotero.org/users/332053/publications/items/DSNAWKSM/file/view},
  abstract = {In this paper, we present ongoing experiments for correcting OCR errors on German newspapers in Fraktur font. Our approach borrows from techniques for spelling correction in context using a probabilistic edit-operation error model and lexical resources. We highlight conditions in which high error reduction rates can be obtained and where the approach currently stands with real data.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/DSNAWKSM/généreux_et_al_2014_correcting_ocr_errors_for_german_in_fraktur_font.pdf}
>>>>>>> 1faf962... Sync
}

@article{glaznieks-EtAl:2014:EstablishingStandardisedProcedure,
  title = {Establishing a {{Standardised Procedure}} for {{Building Learner Corpora}}},
  author = {Glaznieks, Aivars and Abel, Andrea and Lyding, Verena and Nicolas, Lionel and Stemle, Egon},
  editor = {Nikula, Tarja and Takala, Sauli and Ylönen, Sabine},
  date = {2014-12},
  journaltitle = {Apples - Journal of Applied Language Studies},
  volume = {8},
  pages = {5--20},
  publisher = {{Centre for Applied Language Studies, University of Jyväskylä}},
  issn = {1457-9863},
  url = {https://api.zotero.org/users/332053/publications/items/DJINCYPZ/file/view},
  abstract = {Decisions at the outset of preparing a learner corpus are of crucial importance for how the corpus can be built and how it can be analysed later on. This paper presents a generic workflow to build learner corpora while taking into account the needs of the users. The workflow results from an extensive collaboration between linguists that annotate and use the corpus and computer linguists that are responsible for providing technical support. The paper addresses the linguists' research needs as well as the availability and usability of language technology tools necessary to meet them. We demonstrate and illustrate the relevance of the workflow using results and examples from our L1 learner corpus of German ("KoKo").},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/DJINCYPZ/glaznieks_et_al_2014_establishing_a_standardised_procedure_for_building_learner_corpora.pdf},
>>>>>>> 1faf962... Sync
  keywords = {corpus building workflow,German as a first language,L1 learner corpus},
  number = {3}
}

@article{GlaznieksStemle2014,
  title = {Challenges of building a {{CMC}} corpus for analyzing writer's style by age: {{The DiDi}} project},
  author = {Glaznieks, Aivars and Stemle, Egon},
  editor = {Beißwenger, Michael and Oostdijk, Nellek and Storrer, Angelika and family=Heuvel, given=Henk, prefix=van den, useprefix=false},
  date = {2014-12},
  journaltitle = {Journal for Language Technology and Computational Linguistics (JLCL)},
  volume = {29},
  pages = {31--57},
  publisher = {{JLCL}},
  issn = {2190-6858},
  url = {https://api.zotero.org/users/332053/publications/items/B2W4DGRL/file/view},
  abstract = {Special Issue: Building and annotating corpora of computer-mediated discourse. Issues and Challenges at the Inteface of Corpus and Computational Linguistics},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/B2W4DGRL/glaznieks_stemle_2014_challenges_of_building_a_cmc_corpus_for_analyzing_writer's_style_by_age.pdf},
>>>>>>> 1faf962... Sync
  number = {2},
  url_publisher = {https://jlcl.org/}
}

@inproceedings{konig-EtAl:2020:CAC2,
  title = {Technical {{Solutions}} for {{Reproducible Research}}},
  booktitle = {Selected papers from the {{CLARIN Annual Conference}} 2019},
  author = {König, Alexander and Stemle, Egon W. and Moreira, André and Elbers, Willem},
  editor = {Simov, Kiril and Eskevich, Maria},
  date = {2020-07-03},
  volume = {172},
  pages = {66--74},
  publisher = {{Linköping University Electronic Press}},
  location = {{Leipzig, DE}},
  issn = {1650-3740},
  doi = {10.3384/ecp2020172009},
  url = {https://ep.liu.se/ecp/article.asp?issue=172&article=009&volume=0},
  abstract = {In recent years, the reproducibility of scientific research has increasingly come into focus, both by ex ternal stakeholders (e.g. funders) and by the research communities themselves. Corpus linguistics, with its methods for creating, processing and analysing corpora, is an integral part of many other disciplines that work with language data and therefore plays a special role. Moreover, language corpora are often living objects that are regularly improved and revised. At the same time, tools for the automatic processing of human language are also being developed further, which can lead to different results with the same processing steps and the same data. This article argues that modern software technologies, such as version control and containerisation, can mitigate the following problems: Software packaging, installation and execution and, equally important, the tracking of corpus modifications throughout its life-cycle. All in all, this leads to transparency of changes to raw data and software tools and thereby enhanced reproducibility.},
  eventtitle = {{{CLARIN Annual Conference}} 2019},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/67DAJW67/konig_et_al_2020_technical_solutions_for_reproducible_research2.pdf;/home/egon/Books/zotero/linked/König et al/2020_Manuscript/konig_et_al_2020_technical_solutions_for_reproducible_research.pdf},
>>>>>>> 1faf962... Sync
  isbn = {978-91-7929-807-4},
  langid = {english},
  series = {Linköping {{University Electronic Press}}, {{Linköpings}} universitet}
}

@inproceedings{konig-stemle:2019:clarin,
  title = {Technical {{Solutions}} for {{Reproducible Research}}},
  booktitle = {Proceedings of {{CLARIN Annual Conference}} 2019},
  author = {König, Alexander and Stemle, Egon W.},
  editor = {Simov, Kiril and Eskevich, Maria},
  date = {2019-09},
  pages = {89--92},
  publisher = {{CLARIN}},
  location = {{Leipzig, DE}},
  url = {https://api.zotero.org/users/332053/publications/items/D2WMT2UL/file/view},
  abstract = {In recent years, the reproducibility of scientific research has more and more come into focus, both from external stakeholders (e.g. funders) and from within research communities themselves. Corpus linguistics and its methods, which are an integral component of many other disciplines working with language data, play a special role here – language corpora are often living objects: they are constantly being improved and revised, and at the same time, the tools for the automatic processing of human language are also regularly updated, both of which can lead to different results for the same processing steps. This article argues that modern software technologies such as version control and containerization can address both issues, namely make reproducible the process of software packaging, installation, and execution and, more importantly, the tracking of corpora throughout their life cycle, thereby making the changes to the raw data reproducible for many subsequent analyses.},
  eventtitle = {{{CLARIN Annual Conference}} 2019},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/D2WMT2UL/konig_stemle_2019_technical_solutions_for_reproducible_research.pdf;/home/egon/Books/zotero/linked/König_Stemle/2019_Manuscript/konig_stemle_2019_technical_solutions_for_reproducible_research.pdf}
>>>>>>> 1faf962... Sync
}

@inproceedings{KranebitterStemle2013,
  title = {Constructing concept relation maps to support building concept systems in comparative legal terminology},
  booktitle = {{{TOTh}} 2013 {{Proceedings}} - {{Terminology}} \& {{Ontology}}: {{Theories}} and applications},
  author = {Kranebitter, Klara and Stemle, Egon W.},
  editor = {Roche, Christophe and Costa, Rute and Depecker, Loïc and Thoiron, Philippe},
  date = {2013-06},
  pages = {97--116},
  publisher = {{Institut Porphyre, Savoir et Connaissance}},
  location = {{Chamébry, France}},
  url = {https://hal.archives-ouvertes.fr/hal-01354949},
  abstract = {Graphical tools to organise and represent knowledge are useful in terminology work to facilitate building concept systems. Creating and maintaining hierarchically structured concept relation maps while manually gathering data for terminological databases helps to gain and maintain an overview of concept relations, supports terminology work in groups, and helps new team members catching up on the subject field. This article describes our approach to support the building of concept systems in comparative legal terminology using the concept mapping software CmapTools (IHMC): we build hierarchically structured concept relation maps where linking lines with arrowheads between concepts of the same legal system represent generic-specific relations, and combined concept relation maps where dashed lines without arrowheads connect similar concepts in different legal systems.},
  eventtitle = {{{TOTh}} 2013},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/KIU7KGWU/kranebitter_stemle_2013_constructing_concept_relation_maps_to_support_building_concept_systems_in.pdf}
>>>>>>> 1faf962... Sync
}

@inproceedings{leong-EtAl:2020:SFLP,
  title = {A {{Report}} on the 2020 {{VUA}} and {{TOEFL Metaphor Detection Shared Task}}},
  booktitle = {Proceedings of the {{Second Workshop}} on {{Figurative Language Processing}} ({{FigLang2020}})},
  author = {{Chee Wee (Ben) Leong} and {Beata Beigman Klebanov} and {Chris Hamill} and {Egon Stemle} and {Rutuja Ubale} and {Xianyang Chen}},
  date = {2020-07},
  pages = {18--29},
  publisher = {{Association for Computational Linguistics}},
  location = {{Online}},
  url = {https://www.aclweb.org/anthology/2020.figlang-1.3/},
  abstract = {In this paper, we report on the shared task on metaphor identification on VU Amsterdam Metaphor Corpus and on a subset of the TOEFL Native Language Identification Corpus. The shared task was conducted as apart of the ACL 2020 Workshop on Processing Figurative Language.},
  eventtitle = {{{FLP}} @ {{ACL2020}}},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/KQJ7KIPY/chee_wee_(ben)_leong_et_al_2020_a_report_on_the_2020_vua_and_toefl_metaphor_detection_shared_task.pdf}
>>>>>>> 1faf962... Sync
}

@inproceedings{LYDING14.517,
  title = {'{{interHist}}' - an interactive visual interface for corpus exploration},
  booktitle = {Proceedings of the {{Ninth International Conference}} on {{Language Resources}} and {{Evaluation}} ({{LREC}}'14)},
  author = {Lyding, Verena and Nicolas, Lionel and Stemle, Egon},
  editor = {Calzolari, Nicoletta and Choukri, Khalid and Declerck, Thierry and Loftsson, Hrafn and Maegaard, Bente and Mariani, Joseph and Moreno, Asuncion and Odijk, Jan and Stelios, Piperidis},
  date = {2014-05},
  pages = {635--641},
  publisher = {{European Language Resources Association (ELRA)}},
  location = {{Reykjavik, Iceland}},
  url = {http://www.lrec-conf.org/proceedings/lrec2014/pdf/517_Paper.pdf},
  abstract = {In this article, we present interHist, a compact visualization for the interactive exploration of results to complex corpus queries. Integrated with a search interface to the PAISÀ corpus of Italian web texts, interHist aims at facilitating the exploration of large results sets to linguistic corpus searches. This objective is approached by providing an interactive visual overview of the data, which supports the user-steered navigation by means of interactive filtering. It allows to dynamically switch between an overview on the data and a detailed view on results in their immediate textual context, thus helping to detect and inspect relevant hits more efficiently. We provide background information on corpus linguistics and related work on visualizations for language and linguistic data. We introduce the architecture of interHist, by detailing the data structure it relies on, describing the visualization design and providing technical details of the implementation and its integration with the corpus querying environment. Finally, we illustrate its usage by presenting a use case for the analysis of the composition of Italian noun phrases.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/GLVAEHIK/lyding_et_al_2014_'interhist'_-_an_interactive_visual_interface_for_corpus_exploration.pdf},
>>>>>>> 1faf962... Sync
  isbn = {978-2-9517408-8-4},
  keywords = {corpus linguistics,language analysis,visualization}
}

@inproceedings{Lyding2013a,
  title = {Open {{Corpus Interface}} for {{Italian Language Learning}}},
  booktitle = {Proceedings of the {{International Conference ICT}} for {{Language Learning}}, 6th edition},
  author = {Lyding, Verena and Borghetti, Claudia and Dittmann, Henrik and Nicolas, Lionel and Stemle, Egon},
  date = {2013-11-14},
  publisher = {{libreriauniversitaria.it}},
  location = {{Florence, Italy}},
  url = {https://conference.pixel-online.net/conferences/ICT4LL2013/common/download/Paper_pdf/270-ITL56-FP-Lyding-ICT2013.pdf},
  abstract = {In this article, we present the multi-faceted interface to the open PAISÀ corpus of Italian. Created within the project PAISÀ (Piattaforma per l’Apprendimento dell’Italiano Su corpora Annotati) [1], the corpus is designed to be freely available for non-commercial processing, usage and distribution by the public. Hence, this automatically annotated corpus (for lemma, part-of-speech and dependency information) is exclusively composed of documents licensed under Creative Commons (CC) licenses [2].The dedicated corpus interface is designed to provide flexible, powerful, and easy-to-use modes of corpus access, with the objective to support language learning, language practicing and linguistic analyses. We present in detail the interface’s functionalities and discuss the underlying design decisions. We introduce the four principal components of the interface, describe supported display formats and present two specific features added to increase the interface's relevance for language learning. The main search components are (1) a basic search that adopts a "Google-style" search box, (2) an advanced search that provides elaborated graphical search options, and (3) a search that makes use of the powerful CQP query language of the Open Corpus Workbench [3]. In addition, (4) a filter interface for retrieving full-text corpus documents based on keyword searches is available. It is likewise providing the means for building temporary sub-corpora for specific topics. Users can choose among different display formats for the search results. Besides the established KWIC (KeyWord In Context) and full sentence views, graphical representations of the dependency relation information as well as keyword distributions are available. These dynamic displays are based on a visualisation for dependency graphs [4] and one for Word Clouds [5], which build on latest developments in information visualisation for language data. Two special features for novice learners are integrated into each search component. The first feature is a function for restricting search results to sentences of limited complexity. Search results are automatically filtered based on formal text characteristics such as sentence length, vocabulary, etc. The second is the supply of pre-defined search queries for linguistic constructions such as sentences in passive voice, questions, etc. Finally, we show how the PAISÀ interface can be employed in different language teaching tasks. In particular, we present a complete unit of work aimed at learners of Italian (CEFR level A2/B1) and centered on students’ direct use of the interface and its functionalities. By doing so, we are giving concrete examples for targeted searches and interactions with the provided language material, as well as an exemplification of how the use of the corpus can be integrated with communicative language activities in the classroom.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/ZUAGX3XS/lyding_et_al_2013_open_corpus_interface_for_italian_language_learning.pdf},
>>>>>>> 1faf962... Sync
  isbn = {978-88-6292-423-8},
  keywords = {Corpus Linguistics,Linguistic Visualization,Visualization}
}

@inproceedings{murphy-stemle:2011:DIALECTS,
  title = {{{PaddyWaC}}: {{A Minimally}}-{{Supervised Web}}-{{Corpus}} of {{Hiberno}}-{{English}}},
  booktitle = {Proceedings of the {{First Workshop}} on {{Algorithms}} and {{Resources}} for {{Modelling}} of {{Dialects}} and {{Language Varieties}}},
  author = {Murphy, Brian and Stemle, Egon W.},
  date = {2011-07},
  pages = {22--29},
  publisher = {{Association for Computational Linguistics}},
  location = {{Edinburgh, Scotland, UK}},
  url = {https://www.aclweb.org/anthology/W11-2603},
  abstract = {Small, manually assembled corpora may be available for less dominant languages and dialects, but producing web-scale resources remains a challenge. Even when considerable quantities of text are present on the web, finding this text, and distinguishing it from related languages in the same region can be difficult. For example less dominant variants of English (e.g. New Zealander, Singaporean, Canadian, Irish, South African) may be found under their respective national domains, but will be partially mixed with Englishes of the British and US varieties, perhaps through syndication of journalism, or the local reuse of text by multinational companies. Less formal dialectal usage may be scattered more widely over the internet through mechanisms such as wiki or blog authoring. Here we automatically construct a corpus of Hiberno-English (English as spoken in Ireland) using a variety of methods: filtering by national domain, filtering by orthographic conventions, and bootstrapping from a set of Ireland-specific terms (slang, place names, organisations). We evaluate the national specificity of the resulting corpora by measuring the incidence of topical terms, and several grammatical constructions that are particular to Hiberno-English. The results show that domain filtering is very effective for isolating text that is topic-specific, and orthographic classification can exclude some non-Irish texts, but that selected seeds are necessary to extract considerable quantities of more informal, dialectal text.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/FMMXZINQ/murphy_stemle_2011_paddywac.pdf}
>>>>>>> 1faf962... Sync
}

@article{nicolas-EtAl:2014-li,
  title = {A {{Generic Data Workflow}} for {{Building Annotated Text Corpora}}},
  author = {Nicolas, Lionel and Stemle, Egon and Glaznieks, Aivars and Abel, Andrea},
  editor = {Castello, Erik and Ackerley, Katherine and Coccetta, Francesca},
  date = {2015-06},
  journaltitle = {Studies in Learner Corpus Linguistics: Research and Applications for Foreign Language Teaching and Assessment},
  volume = {190},
  pages = {337--351},
  publisher = {{Peter Lang}},
  location = {{Bern, CH}},
  doi = {10.3726/978-3-0351-0736-4},
  abstract = {We present an abstract and generic workflow, and detail how it has been implemented to build and annotate learner corpora. This workflow has been developed through an interdisciplinary collaboration between linguists, who annotate and use corpora, and computational linguists and computer scientists, who are responsible for providing technical support and adaptation or implementation of software components.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/HZ9WGRBP/nicolas_et_al_2015_a_generic_data_workflow_for_building_annotated_text_corpora.pdf;/home/egon/Books/zotero/linked/Peter Lang/2015/nicolas_et_al_2015_a_generic_data_workflow_for_building_annotated_text_corpora.pdf},
>>>>>>> 1faf962... Sync
  isbn = {978-3-0351-0736-4},
  series = {Linguistic {{Insights}}},
  urlpdf = {https://api.zotero.org/users/332053/publications/items/HZ9WGRBP/file/view},
  urltype = {publisher}
}

@inproceedings{Nicolas2013a,
  title = {High-{{Accuracy Phrase Translation Acquisition Through Battle}}-{{Royale Selection}}},
  booktitle = {Proceedings of {{Recent Advances}} in {{Natural Language Processing}}, {{RANLP}} 2013},
  author = {Nicolas, Lionel and Stemle, Egon W. and Kranebitter, Klara and Lyding, Verena},
  editor = {Angelova, Galia and Bontcheva, Kalina and Mitkov, Ruslan},
  date = {2013-09},
  pages = {516--524},
  publisher = {{RANLP 2011 Organising Committee / ACL}},
  location = {{Hissar, Bulgaria}},
  url = {http://aclweb.org/anthology/R/R13/R13-1068.pdf},
  urldate = {2013-12-13},
  abstract = {In this paper, we report on an unsupervised greedy-style process for acquiring phrase translations from sentence-aligned parallel corpora. Thanks to innovative selection strategies, this process can acquire multiple translations without size criteria, i.e. phrases can have several translations, can be of any size, and their size is not considered when selecting their translations. Even though the process is in an early development stage and has much room for improvements, evaluation shows that it yields phrase translations of high precision that are relevant to machine translation but also to a wider set of applications including memory-based translation or multi-word acquisition.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/56TDUTP4/nicolas_et_al_2013_high-accuracy_phrase_translation_acquisition_through_battle-royale_selection.pdf},
>>>>>>> 1faf962... Sync
  keywords = {Bilingual lexicon,Parallel Corpora,Phrase Translation,Unsupervised Learning}
}

@inproceedings{NicolasStemleKranebitter2012,
  title = {Towards high-accuracy bilingual phrase acquisition from parallel corpora},
  booktitle = {Proceedings of the 11th {{Conference}} on {{Natural Language Processing}}, {{KONVENS}} 2012, {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Nicolas, Lionel and Stemle, Egon W. and Kranebitter, Klara},
  editor = {Jancsary, Jeremy},
  date = {2012-09},
  pages = {471--479},
  publisher = {{ÖGAI}},
  location = {{Vienna, Austria}},
  url = {https://api.zotero.org/users/332053/publications/items/SK4UUA5L/file/view},
  abstract = {We report on on-going work to derive translations of phrases from parallel corpora. We describe an unsupervised and knowledge-free greedy-style process relying on innovative strategies for choosing and discarding candidate translations. This process manages to acquire multiple translations combining phrases of equal or different sizes. The preliminary evaluation performed confirms both its potential and its interest.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/SK4UUA5L/nicolas_et_al_2012_towards_high-accuracy_bilingual_phrase_acquisition_from_parallel_corpora.pdf},
>>>>>>> 1faf962... Sync
  keywords = {Bilingual lexicon,Parallel Corpora,Phrase Translation,Unsupervised Learning}
}

@inproceedings{paisa2014,
  title = {The {{PAISÀ Corpus}} of {{Italian Web Texts}}},
  booktitle = {Proceedings of the 9th {{Web}} as {{Corpus Workshop}} ({{WaC}}-9)},
  author = {Lyding, Verena and Stemle, Egon and Borghetti, Claudia and Brunello, Marco and Castagnoli, Sara and Orletta, Felice Dell and Dittmann, Henrik and Lenci, Alessandro and Pirrelli, Vito},
  date = {2014-04-26},
  pages = {36--43},
  publisher = {{Association for Computational Linguistics}},
  location = {{Gothenburg, Sweden}},
  url = {https://www.aclweb.org/anthology/W14-0406/},
  abstract = {PAISÀ is a Creative Commons licensed, large web corpus of contemporary Italian. We describe the design, harvesting, and processing steps involved in its creation.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/PVUA9TJD/lyding_et_al_2014_the_paisà_corpus_of_italian_web_texts.pdf}
>>>>>>> 1faf962... Sync
}

@inproceedings{poesio-EtAl:2011:LaTeCH-2011,
  title = {Structure-{{Preserving Pipelines}} for {{Digital Libraries}}},
  booktitle = {Proceedings of the 5th {{ACL}}-{{HLT Workshop}} on {{Language Technology}} for {{Cultural Heritage}}, {{Social Sciences}}, and {{Humanities}} ({{LaTeCH}} 2011)},
  author = {Poesio, Massimo and Barbu, Eduard and Stemle, Egon W. and Girardi, Christian},
  date = {2011-06},
  pages = {54--62},
  publisher = {{Association for Computational Linguistics}},
  location = {{Portland, OR, USA}},
  url = {https://www.aclweb.org/anthology/W11-1508/},
  abstract = {Most existing HLT pipelines assume the input is pure text or, at most, HTML and either ignore (logical) document structure or remove it. We argue that identifying the structure of documents is essential in digital library and other types of applications, and show that it is relatively straightforward to extend existing pipelines to achieve ones in which the structure of a document is preserved.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/S5CXSY2N/poesio_et_al_2011_structure-preserving_pipelines_for_digital_libraries.pdf}
>>>>>>> 1faf962... Sync
}

@inproceedings{PoesioSDH2011,
  title = {The {{Humanities Research Portal}}: {{Human Language Technology Meets Humanities Publication Archives}}},
  booktitle = {Proceedings of {{Supporting Digital Humanities}} ({{SDH2011}}): {{Answering}} the unaskable},
  author = {Poesio, Massimo and Barbu, Eduard and Bonin, Francesca and Cavulli, Fabio and Ekbal, Asif and Stemle, Egon and Girardi, Christian},
  editor = {Maegaard, Bente},
  date = {2011-11},
  location = {{Copenhagen, Denmark}},
  url = {https://api.zotero.org/users/332053/publications/items/V6YCU92Y/file/view},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/V6YCU92Y/poesio_et_al_2011_the_humanities_research_portal.pdf}
>>>>>>> 1faf962... Sync
}

@inproceedings{RodriguezDeloguVersleyStemlePoesio2010,
  title = {Anaphoric {{Annotation}} of {{Wikipedia}} and {{Blogs}} in the {{Live Memories Corpus}}},
  booktitle = {Proceedings of the {{Seventh Conference}} on {{International Language Resources}} and {{Evaluation}} ({{LREC}}'10)},
  author = {Rodríguez, Kepa Joseba and Delogu, Francesca and Versley, Jannick and Stemle, Egon W. and Poesio, Massimo},
  editor = {Calzolari, Nicoletta and Choukri, Khalid and Maegaard, Bente and Mariani, Joseph and Odijk, Jan and Piperidis, Stelios and Rosner, Mike and Tapias, Daniel},
  date = {2010-05},
  publisher = {{European Language Resources Association (ELRA)}},
  location = {{Valletta, Malta}},
  url = {http://www.lrec-conf.org/proceedings/lrec2010/pdf/431_Paper.pdf},
<<<<<<< HEAD
=======
  file = {/home/egon/Books/zotero/linked/Rodríguez et al/2010_Conference Paper/rodriguez_et_al_2010_anaphoric_annotation_of_wikipedia_and_blogs_in_the_live_memories_corpus.pdf},
>>>>>>> 1faf962... Sync
  isbn = {2-9517408-6-7}
}

@inproceedings{StegerStemle2009,
  title = {{{KrdWrd}}: {{Architecture}} for {{Unified Processing}} of {{Web Content}}},
  booktitle = {Proceedings of the {{Fifth Web}} as {{Corpus Workshop}} ({{WAC5}})},
  author = {Steger, Johannes and Stemle, Egon},
  editor = {Alegria, Iñaki and Leturia, Igor and Sharoff, Serge},
  date = {2009-09},
  pages = {63--70},
  publisher = {{Elhuyar Fundazioa}},
  location = {{Donostia-San Sebastian, Basque Country, Spain}},
  url = {https://www.sigwac.org.uk/raw-attachment/wiki/WAC5/WAC5_proceedings.pdf},
  abstract = {Algorithmic processing of Web content mostly works on textual contents, neglecting visual information. Annotation tools largely share this deficit as well. We specify requirements for an architecture to overcome both problems and propose an implementation, the KrdWrd system. It uses the Gecko rendering engine for both annotation and feature extraction, providing unified data access in every processing step. Stable data storage and collaboration control scripts for group annotations of massive corpora are provided via a Web interface coupled with a HTTP proxy. A modular interface allows for linguistic and visual data feature extractor plugins. The implementation is suitable for many tasks in theWeb as corpus domain and beyond.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/G2UG9L3P/steger_stemle_2009_krdwrd.pdf}
>>>>>>> 1faf962... Sync
}

@inproceedings{stemle-EtAl:2019:elex,
  title = {Language varieties meet {{One}}-{{Click Dictionary}}},
  booktitle = {Electronic lexicography in the 21st century. {{Proceedings}} of the {{eLex}} 2019 conference},
  author = {Stemle, Egon W. and Abel, Andrea and Lyding, Verena},
  editor = {{Iztok Kosem} and {Tanara Zingano Kuhn} and {Margarita Correia} and {José Pedro Ferreira} and {Maarten Jansen} and {Isabel Pereira} and {Jelena Kallas} and {Miloš Jakubíček} and {Simon Krek} and {Carole Tiberius}},
  date = {2019-10},
  pages = {537--546},
  publisher = {{Lexical Computing CZ s.r.o., Brno, CZ}},
  location = {{Sintra, PT}},
  issn = {2533-5626},
  url = {https://elex.link/elex2019/wp-content/uploads/2019/09/eLex_2019_31.pdf},
  abstract = {The goal of the STyrLogism Project is to semi-automatically extract neologism candidates (new lexemes) for the German standard variety used in South Tyrol, and generally create the basis for long-term monitoring of its development. We use automatic lexico-semantic analytics for the lexicographic processing, but instead of continuing to develop our independent neologism detection application, we have recently become part of a thriving community of users and developers within the EU infrastructure project ELEXIS, which aims to harmonise efforts that relate to producing and making dictionary resources available, and to develop tools with consistent standards and increased interoperability. Consequently, we moved the development of our neologism application into Lexonomy, one of ELEXIS' promoted open-source projects. In the following, we report on the current state of this ongoing development by describing how we integrate our work with the Sketch Engine and Lexonomy tools, pointing out the challenges involved, and discussing how our work on language varieties can be evaluated.},
  eventtitle = {{{eLex}} 2019: {{Smart Lexicography}}},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/3WGU7D45/stemle_et_al_2019_language_varieties_meet_one-click_dictionary.pdf}
>>>>>>> 1faf962... Sync
}

@article{stemle-EtAl:2019:lcr-postconf,
  title = {Working together towards an ideal infrastructure for language learner corpora},
  author = {Stemle, Egon W. and Boyd, Adriane and Janssen, Maarten and Lindström Tiedemann, Therese and Mikelić Preradović, Nives and Rosen, Alexandr and Rosén, Dan and Volodina, Elena},
  editor = {Abel, Andrea and Glaznieks, Aivars and Lyding, Verena and Nicolas, Lionel},
  date = {2019-10-24},
  journaltitle = {Widening the Scope of Learner Corpus Research. Selected Papers from the Fourth Learner Corpus Research Conference 2017},
  pages = {437--478},
  publisher = {{Presses universitaires de Louvain}},
  issn = {20346417},
  url = {https://pul.uclouvain.be/book/?gcoi=29303100798060},
  urldate = {2020-03-24},
  abstract = {In this article we give an overview of first-hand experiences and starting points for best practices from projects in seven European countries dedicated to learner corpus research and the creation of language learner corpora. The corpora and tools involved in LCR are becoming more and more important, and the careful preparation and easy retrieval, and reusability of corpora and tools has likewise become more important. But with a lack of agreed solutions for many aspects of LCR, interoperability between learner corpora or exchanging data from different learner corpus projects is still challenging. We will illustrate how concepts like metadata, anonymization, error taxonomies and linguistic annotations, as well as tools, toolchains or data formats can individually pose challenges and how they might be solved.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/VIRDP7JJ/stemle_et_al_2019_working_together_towards_an_ideal_infrastructure_for_language_learner_corpora.pdf;/home/egon/Books/zotero/linked/Stemle et al/2019_Journal Article/stemle_et_al_2019_working_together_towards_an_ideal_infrastructure_for_language_learner_corpora.pdf},
>>>>>>> 1faf962... Sync
  series = {Corpora and {{Language}} in {{Use}}},
  urlpdf = {https://api.zotero.org/users/332053/publications/items/VIRDP7JJ/file/view},
  urltype = {publisher}
}

@article{stemle-onysko:2014,
  title = {Automated {{L1}} identification in {{English}} learner essays and its implications for language transfer},
  author = {Stemle, Egon and Onysko, Alexander},
  editor = {Peukert, Hagen},
  date = {2015-04},
  journaltitle = {Transfer Effects in Multilingual Language Development},
  volume = {4},
  pages = {297--321},
  publisher = {{John Benjamins}},
  doi = {10.1075/hsld.4.13ste},
  url = {https://benjamins.com/catalog/hsld.4.13ste},
  abstract = {This article focuses on automatic text classification which aims at identifying the first language (L1) background of learners of English. A particular question arising in the context of automated L1 identification is whether any features that are informative for a machine learning algorithm relate to L1-specific transfer phenomena. In order to explore this issue further, we discuss the results of a study carried out in the wake of a Native Language Identification Task. The task is based on the TOEFL11 corpus (cf. Blanchard et al. 2013), which involves a sample of 12,100 essays written by participants in the TOEFL® test from 11 different language backgrounds (Arabic, Chinese, French, German, Hindi, Italian, Japanese, Korean, Spanish, Telugu, and Turkish). The article will show our results in automatic L1 detection in the TOEFL11 corpus. These results are discussed in light of relevant transfer features which turned out to be particularly informative for automatic detection of L1 German and L1 Italian.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/QI8K3E4I/stemle_onysko_2015_automated_l1_identification_in_english_learner_essays_and_its_implications_for.pdf;/home/egon/Books/zotero/linked/Transfer Effects in Multilingual Language Development/2015/stemle_onysko_2015_automated_l1_identification_in_english_learner_essays_and_its_implications_for.pdf},
>>>>>>> 1faf962... Sync
  series = {Hamburg {{Studies}} on {{Linguistic Diversity}}},
  urlpdf = {https://api.zotero.org/users/332053/publications/items/QI8K3E4I/file/view},
  urltype = {publisher}
}

@inproceedings{stemle-onysko:2018:naacl-flpst,
  title = {Using {{Language Learner Data}} for {{Metaphor Detection}}},
  booktitle = {Proceedings of the {{Workshop}} on {{Figurative Language Processing}}},
  author = {Stemle, Egon and Onysko, Alexander},
  date = {2018-06},
  pages = {133--138},
  publisher = {{Association for Computational Linguistics}},
  location = {{New Orleans, LA}},
  doi = {10.18653/v1/W18-0918},
  url = {http://aclweb.org/anthology/W18-0918},
  abstract = {This article describes the system that participated in the shared task (ST) on metaphor detection on the Vrije University Amsterdam Metaphor Corpus (VUA). The ST was part of the workshop on processing figurative language at the 16th annual conference of the North American Chapter of the Association for Computational Linguistics (NAACL2018). The system combines a small assertion of trending techniques, which implement matured methods from NLP and ML; in particular, the system uses word embeddings from standard corpora and from corpora representing different proficiency levels of language learners in a LSTM BiRNN architecture. The system is available under the APLv2 open-source license.},
  eventtitle = {Workshop on {{Figurative Language Processing}}},
<<<<<<< HEAD
=======
  file = {/home/egon/Books/zotero/linked/Association for Computational Linguistics/2018/stemle_onysko_2018_using_language_learner_data_for_metaphor_detection.pdf}
>>>>>>> 1faf962... Sync
}

@inproceedings{stemle-onysko:2020:SFLP,
  title = {Testing the role of metadata in metaphor identification},
  booktitle = {Proceedings of the {{Second Workshop}} on {{Figurative Language Processing}} ({{FigLang2020}})},
  author = {Stemle, Egon W. and Onysko, Alexander},
  date = {2020-07},
  pages = {256--263},
  publisher = {{Association for Computational Linguistics}},
  location = {{Online}},
  url = {https://www.aclweb.org/anthology/2020.figlang-1.35},
  abstract = {This paper describes the adaptation and application of a neural network system for the automatic detection of metaphors. The  LSTM BiRNN system participated in the shared task of metaphor identification that was part of the Second Workshop of Figurative Language Processing (FigLang2020) held at the Annual Conference of the Association for Computational Linguistics (ACL2020). The particular focus of our approach is on the potential influence that the metadata given in the ETS Corpus of Non-Native Written English might have on the automatic detection of metaphors in this dataset. The article first discusses the annotated ETS learner data, highlighting some of its peculiarities and inherent biases of metaphor use. A series of evaluations follow in order to test whether specific metadata influence the system performance in the task of automatic metaphor identification. The system is available under the APLv2 open-source license.},
  eventtitle = {The {{Second Workshop}} on {{Figurative Language Processing}} ({{FigLang2020}}) @ {{ACL2020}}},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/DDWDMDP6/stemle_onysko_testing_the_role_of_metadata_in_metaphor_identification.pdf}
>>>>>>> 1faf962... Sync
}

@report{stemle:2016:enel-stsm,
  title = {Scientific {{Report}} of {{Short Term Scientific Mission COST}}-{{STSM}}-{{IS1305}}-34353},
  author = {Stemle, Egon W.},
  date = {2016-09},
  institution = {{EURAC (Bolzano, IT) and Centre for Language Resources and Technologies (Ljubljana, SI)}},
  location = {{Ljubljana, SI}},
  url = {http://www.elexicography.eu/wp-content/uploads/2017/02/ScientificReportSTSM-IS1305-34353-EgonStemle.pdf},
  abstract = {ENeL's WG3 concerns innovative e-dictionaries with a focus on the development of digitally born dictionaries. The training school 2016 in Ljubljana (SI), May 17-20, introduced parti­cipants, among others, to collecting, analysing, and automatically extracting data from web corpora. Albeit related, the task of processing data from corpora of computer-mediated communica­tion and social media interactions (henceforth referred to as CMC) has been deliberately ex­cluded from the training school's programme. But we know that "new vocabulary is charac­teristic for CMC discourse, e.g. ‘funzen’ (an abbreviated variant of the German verb ‘funk­tionieren’, en.: ‘to function’) or ‘gruscheln’ (verb denoting a function of a German social net­work platform, most likely a blending of ‘grüßen’, en.: ‘to greet’ and ‘kuscheln’, en.: ‘to cuddle’)" and therefore relevant to WG3; the goal of this STSM is to apply the meth­ods and tools from the training school to CMC data.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/X2A4HBR5/stemle_2016_scientific_report_of_short_term_scientific_mission_cost-stsm-is1305-34353.pdf}
>>>>>>> 1faf962... Sync
}

@inproceedings{stemle:2016:evalita,
  title = {bot.zen @ {{EVALITA}} 2016 - {{A}} minimally-deep learning {{PoS}}-tagger (trained for {{Italian Tweets}})},
  booktitle = {Proceedings of {{Third Italian Conference}} on {{Computational Linguistics}} ({{CLiC}}-it 2016) \& {{Fifth Evaluation Campaign}} of {{Natural Language Processing}} and {{Speech Tools}} for {{Italian}}. {{Final Workshop}} ({{EVALITA}} 2016)},
  author = {Stemle, Egon W.},
  editor = {Basile, Pierpaolo and Corazza, Anna and Cutugno, Franco and Montemagni, Simonetta and Nissim, Malvina and Patti, Viviana and Semeraro, Giovanni and Sprugnoli, Rachele},
  date = {2016-12},
  publisher = {{Accademia University Press}},
  location = {{Napoli, Italy}},
  doi = {10.4000/books.aaccademia.1968},
  url = {http://books.openedition.org/aaccademia/pdf/1968},
  abstract = {This article describes the system that participated in the POS tagging for Italian Social Media Texts (PoSTWITA) task of the 5th periodic evaluation campaign of Natural Language Processing (NLP) and speech tools for the Italian language EVALITA 2016. The work is a continuation of Stemle (2016) with minor modifications to the system and different data sets. It combines a small assertion of trending techniques, which implement matured methods, from NLP and ML to achieve competitive results on PoS tagging of Italian Twitter texts; in particular, the system uses word embeddings and character-level representations of word beginnings and endings in a LSTM RNN architecture. Labelled data (Italian UD corpus, DiDi and PoSTWITA) and unlabbelled data (Italian C4Corpus and PAISA') were used for training. The system is available under the APLv2 open-source license.},
  eventtitle = {{{EVALITA}}},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/BALSJ4X5/stemle_2016_bot.pdf}
>>>>>>> 1faf962... Sync
}

@inproceedings{stemle:2016:WAC-X,
  title = {bot.zen @ {{EmpiriST}} 2015 - {{A}} minimally-deep learning {{PoS}}-tagger (trained for {{German CMC}} and {{Web}} data)},
  booktitle = {Proceedings of the 10th {{Web}} as {{Corpus Workshop}} ({{WAC}}-{{X}}) and the {{EmpiriST Shared Task}}},
  author = {Stemle, Egon W.},
  editor = {Cook, Paul and Evert, Stefan and Schäfer, Roland and Stemle, Egon},
  date = {2016-08},
  pages = {115--119},
  publisher = {{Association for Computational Linguistics}},
  url = {http://anthology.aclweb.org/W/W16/W16-2614.pdf},
  abstract = {This article describes the system that participated in the Part-of-speech tagging subtask of the "EmpiriST 2015 shared task on automatic linguistic annotation of computer-mediated communication / social media". The system combines a small assertion of trending techniques, which implement matured methods, from NLP and ML to achieve competitive results on PoS tagging of German CMC and Web corpus data; in particular, the system uses word embeddings and character-level representations of word beginnings and endings in a LSTM RNN architecture. Labelled data (Tiger v2.2 and EmpiriST) and unlabelled data (German Wikipedia) were used for training. The system is available under the APLv2 open-source license.},
  eventtitle = {{{WAC}}-{{X}}},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/BPV75ICF/stemle_2016_bot.pdf}
>>>>>>> 1faf962... Sync
}

@thesis{Stemle2009,
  title = {Hybrid {{Sweeping}}: {{Streamlined Perceptual Structured}}-{{Text Refinement}}},
  author = {Stemle, Egon W.},
  date = {2009-04},
  institution = {{University of Osnabrück}},
  url = {https://api.zotero.org/users/332053/publications/items/E4KQVSBJ/file/view},
  abstract = {This thesis discusses the KrdWrd Project. The Project goals are to provide tools and infrastructure for acquisition, visual annotation, merging and storage of Web pages as parts of bigger corpora, and to develop a classification engine that learns to automatically annotate pages, operate on the visual rendering of pages, and provide visual tools for inspection of results.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/E4KQVSBJ/stemle_2009_hybrid_sweeping.pdf},
>>>>>>> 1faf962... Sync
  type = {Unpublished master's thesis}
}

@article{StemleOnysko:2013:LanguageDetectiveStory,
  title = {Language as a {{Detective Story}}},
  author = {Stemle, Egon W. and Onysko, Alexander},
  date = {2013-12},
  journaltitle = {Academia},
  volume = {64},
  pages = {24--25},
  url = {https://api.zotero.org/users/332053/publications/items/DS4NFSQ2/file/view},
  abstract = {Article in Academia (science magazine by EURAC and unibz), Bolzano, Italy},
  entrysubtype = {newspaper},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/DS4NFSQ2/stemle_onysko_2013_language_as_a_detective_story.pdf},
>>>>>>> 1faf962... Sync
  type = {magazine}
}

@book{wac-2020-web,
  title = {Proceedings of the 12th {{Web}} as {{Corpus Workshop}}},
  author = {Barbaresi, Adrien and Bildhauer, Felix and Schäfer, Roland and Stemle, Egon},
  date = {2020-05},
  publisher = {{European Language Resources Association}},
  location = {{Marseille, FR}},
  url = {https://www.aclweb.org/anthology/volumes/2020.wac-1/},
  abstract = {For almost fifteen years, the ACL SIGWAC, and most notably the Web as Corpus (WAC) workshops, have served as a platform for researchers interested in the compilation, processing and use of webderived corpora as well as computer-mediated communication. Past workshops were co-located with major conferences on corpus linguistics and computational linguistics (such as ACL, EACL, Corpus Linguistics, LREC, NAACL, WWW). In corpus linguistics and theoretical linguistics, the World Wide Web has become increasingly popular as a source of linguistic evidence, especially in the face of data sparseness or the lack of variation in traditional corpora of written language. In lexicography, web data have become a major and wellestablished resource with dedicated research data and specialised tools. In other areas of theoretical linguistics, the adoption rate of web corpora has been slower but steady. Furthermore, some completely new areas of linguistic research dealing exclusively with web (or similar) data have emerged, such as the construction and utilisation of corpora based on short messages. Another example is the (manual or automatic) classification of web texts by genre, register, or – more generally speaking – “text type”, as well as topic area. In computational linguistics, web corpora have become an established source of data for the creation of language models, word embeddings, and all types of machine learning. The 12th Web as Corpus workshop (WAC-XII) looks at the past, present, and future of web corpora given the fact that large web corpora are nowadays provided mostly by a few major initiatives and companies, and the diversity of the early years appears to have faded slightly. Also, we acknowledge the fact that alternative sources of data (such as data from Twitter and similar platforms) have emerged, some of them only available to large companies and their affiliates, such as linguistic data from social media and other forms of the deep web. At the same time, gathering interesting and relevant web data (web crawling) is becoming an ever more intricate task as the nature of the data offered on the web changes (for example the death of forums in favour of more closed platforms).},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/R3TGW5RP/barbaresi_et_al_2020_proceedings_of_the_12th_web_as_corpus_workshop.pdf},
>>>>>>> 1faf962... Sync
  isbn = {979-10-95546-68-9}
}

@book{WAC-X:2016,
  title = {Proceedings of the 10th {{Web}} as {{Corpus Workshop}} ({{WAC}}-{{X}}) and the {{EmpiriST Shared Task}}},
  editor = {Cook, Paul and Evert, Stefan and Schäfer, Roland and Stemle, Egon},
  date = {2016-08},
  publisher = {{Association for Computational Linguistics}},
  location = {{Berlin}},
  url = {http://aclweb.org/anthology/W16-26},
  abstract = {The World Wide Web has become increasingly popular as a source of linguistic data, not only within the NLP communities, but also with theoretical linguists facing problems of data sparseness or data diversity. Accordingly, web corpora continue to gain importance, given their size and diversity in terms of genres/text types. The field is still new, though, and a number of issues in web corpus construction need much additional research, both fundamental and applied. These issues range from questions of corpus design (e.g., assessment of corpus composition, sampling strategies and their relation to crawling algorithms, and handling of duplicated material) to more technical aspects (e.g., efficient implementation of individual post-processing steps in document cleaning and linguistic annotation, or large-scale parallelization to achieve web-scale corpus construction). Similarly, the systematic evaluation of web corpora, for example in the form of task based comparisons to traditional corpora, has only recently shifted into focus. For almost a decade, the ACL SIGWAC (http://www.sigwac.org.uk/), and especially the highly successful Web as Corpus (WAC) workshops have served as a platform for researchers interested in compilation, processing and application of web-derived corpora. Past workshops were co-located with major conferences on computational linguistics and/or corpus linguistics (such as EACL, NAACL, LREC, WWW, and Corpus Linguistics). WAC-X also featured the final workshop of the EmpiriST 2015 shared task "Automatic Linguistic Annotation of Computer-Mediated Communication / Social Media" (see https://sites.google.com/site/empirist2015/ for details) and the panel discussion "Corpora, open science, and copyright reforms" (see https://www.sigwac.org.uk/wiki/WAC-X\#paneldisc for details).},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/7M7ESMFK/cook_et_al_2016_proceedings_of_the_10th_web_as_corpus_workshop_(wac-x)_and_the_empirist_shared.pdf},
>>>>>>> 1faf962... Sync
  isbn = {978-1-945626-15-9},
  type = {proceedings}
}

@book{WAC8,
  title = {Proceedings of the 8th {{Web}} as {{Corpus Workshop}} ({{WAC}}-8)},
  editor = {Evert, Stefan and Stemle, Egon and Rayson, Paul},
  date = {2013-07-22},
  publisher = {{WAC-8 Organising Committee}},
  location = {{Lancaster, UK}},
  url = {http://sigwac.org.uk/raw-attachment/wiki/WAC8/wac8-proceedings.pdf},
  abstract = {Web corpora and other Web-derived data have become a gold mine for corpus linguistics and natural language processing. The Web is an easy source of unprecedented amounts of linguistic data from a broad range of registers and text types. However, a collection of Web pages is not immediately suitable for exploration in the same way a traditional corpus is. Since the first Web as Corpus Workshop organised at the Corpus Linguistics 2005 Conference, a highly successful series of yearly Web as Corpus workshops provides a venue for interested researchers to meet, share ideas and discuss the problems and possibilities of compiling and using Web corpora. After a stronger focus on application-oriented natural language processing andWeb technology in recent years with workshops taking place at NAACL-HLT 2010, 2011 andWWW2012 the 8thWeb as Corpus Workshop returns to its roots in the corpus linguistics community. Accordingly, the leading theme of this workshop is the application of Web data in language research, including linguistic evaluation of Web-derived corpora as well as strategies and tools for high-quality automatic annotation ofWeb text. The workshop brings together presentations on all aspects of building, using and evaluating Web corpora, with a particular focus on the following topics: applications of Web corpora and other Web-derived data sets for language research automatic linguistic annotation of Web data such as tokenisation, part-of-speech tagging, lemma- tisation and semantic tagging (the accuracy of currently available off-the-shelf tools is still unsatisfactory for many types of Web data) critical exploration of the characteristics of Web data from a linguistic perspective and its applica- bility to language research presentation of Web corpus collection projects or software tools required for some part of this process (crawling, filtering, de-duplication, language identification, indexing, ...)},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/PZQX2T28/evert_et_al_2013_proceedings_of_the_8th_web_as_corpus_workshop_(wac-8).pdf},
>>>>>>> 1faf962... Sync
  type = {proceedings}
}

@book{wigham-stemle:2019:cmc17volume,
  title = {Building {{Computer}}-{{Mediated Communication Corpora}} for sociolinguistic {{Analysis}}},
  editor = {Wigham, Ciara R. and Stemle, Egon W.},
  date = {2019-06-13},
  publisher = {{Presses Universitaires Blaise Pascal}},
  location = {{Clermont-Ferrand, FR}},
  url = {http://pubp.giantchair.com/livre/?GCOI=28451100141150&language=en},
  abstract = {Communication between humans via networked devices has become an everyday part of people's lives across generations, cultures, geographical areas, and social classes. Shaped by the specific social and technical context in which it is produced, synchronous and asynchronous computer-mediated communication (CMC) has become increasingly participatory, interactive, and multimodal. User interactions and user-generated social media content offer a wide range of research opportunities for a growing multidisciplinary research community. This edited volume combines methodological papers that focus on building and annotating CMC corpora and papers that offer a sociolinguistic analysis of different CMC corpora. The diversity of languages represented in the corpora include Arabic, French, German, Italian, English and Slovenian. In fact, the increasingly multilingual nature of CMC data is a recurring theme throughout the volume, as are the references to the importance of and compliance with standards for CMC corpora development in order to facilitate (the?) re-examination of corpora for reproducibility, and for other areas and objectives of investigation. All but one paper are extended papers from the 2017 edition of the CMC and Social Media Corpora Conference held in Bolzano, Italy where the community met to discuss themes that related to the interaction between language, CMC, and society.},
<<<<<<< HEAD
=======
  file = {/home/egon/.zotero/data/storage/VUCHGUTC/wigham_stemle_2019_building_computer-mediated_communication_corpora_for_sociolinguistic_analysis.pdf},
>>>>>>> 1faf962... Sync
  isbn = {978-2-84516-860-2},
  langid = {english},
  pagetotal = {155},
  series = {Cahiers du laboratoire de recherche sur le langage},
  urltype = {publisher}
}


